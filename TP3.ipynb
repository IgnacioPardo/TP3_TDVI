{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuración\n",
    "\n",
    "Crearse una cuenta en Weights and Biases (o en su board favorito) y linkear la notebook a este. Cada experimento deberá contener nombres dicientes y almacenar los (hiper)parámetros de configuración del mismo. Deberá separar los sets de datos en entrenamiento, validación y test. Utilizando solamente los sets de entrenamiento y validación, registrar la loss en train y validación en cada iteración que considere conveniente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchview torchviz graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, CosineAnnealingLR\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchview import draw_graph\n",
    "from torchviz import make_dot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "import ssl\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El backend para correr con la GPU de los procesadores M1 de Apple es Metal, por lo que setiamos el device a MPS\n",
    "# Para correr con la GPU T4 de Google Colab, o con la 1080 TI de la PC, setiamos el device a CUDA\n",
    "\n",
    "device = torch.device(\n",
    "    'mps:0' if torch.backends.mps.is_available() else 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mignacio-pardo\u001b[0m (\u001b[33mpardo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequeamos si la carpeta data existe, si no existe la creamos\n",
    "download = not os.path.isdir('./data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(181988)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(181988)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "end_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_224 = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set y Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargamos el dataset CIFAR10 y lo guardamos en la variable train_set\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=download, transform=end_transform\n",
    ")\n",
    "\n",
    "# Guardamos en targets_ las etiquetas de las imágenes del dataset\n",
    "targets_ = train_set.targets\n",
    "\n",
    "# Dividimos el dataset en train y validation\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(targets_)), test_size=0.2, stratify=targets_\n",
    ")\n",
    "\n",
    "# Creamos los samplers para train y validation\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "\n",
    "# Creamos los dataloaders para train y validation\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, sampler=train_sampler, batch_size=batch_size, num_workers=2\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    train_set, sampler=val_sampler, batch_size=batch_size, num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargamos el dataset CIFAR10 y lo guardamos en la variable test_set\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=download, transform=end_transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_transforms(transform):\n",
    "    global train_loader\n",
    "    global test_loader\n",
    "    global val_loader\n",
    "\n",
    "    train_loader.dataset.transform = transform\n",
    "    test_loader.dataset.transform = transform\n",
    "    val_loader.dataset.transform = transform\n",
    "\n",
    "def get_transforms():\n",
    "    return train_loader.dataset.transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model):\n",
    "    global test_loader, device\n",
    "\n",
    "    model_arch = model.__class__.__name__\n",
    "    print(f\"Visualizing {model_arch} model\")\n",
    "\n",
    "    if model_arch in [\"VGG16\", \"VGG19\", \"ResNet\", \"InceptionNet_V1\"]:\n",
    "        set_transforms(transform_224)\n",
    "        dataiter = iter(test_loader)\n",
    "        data = next(dataiter)\n",
    "        test_images, _ = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # if model_arch == \"InceptionNet_V1\":\n",
    "            # x = torch.squeeze(test_images[0:10], 0)\n",
    "        # else:\n",
    "        x = test_images[0]\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        x = x.to(device)\n",
    "    else:\n",
    "        x = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "    y = model(x)\n",
    "\n",
    "    make_dot(y, params=dict(model.named_parameters())).render(f\"plots/{model_arch}/dot.gv\", view=True)\n",
    "\n",
    "    nn_graph = draw_graph(model, x, expand_nested=True)\n",
    "    nn_graph.visual_graph.render(f\"plots/{model_arch}/graph.gv\", view=True)\n",
    "    nn_graph.visual_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Funcion para mostrar imagenes\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Tomar imagenes random\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Mostramos imagenes\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "imshow(grid)\n",
    "\n",
    "# Printeamos las etiquetas de las imagenes\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "\n",
    "image_size = images[0].shape\n",
    "image_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Arquitectura\n",
    "\n",
    "Realizar experimentos variando cantidad de capas densas, nodos, hidden layers y reportar el mejor y peor experimento. ¿Qué estrategia utilizaron? ¿Qué resultados obtuvieron?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "#### Softmax Dropout Relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 32 * 32 * 3)\n",
    "        self.fc21 = nn.Linear(32 * 32 * 3, 32 * 32)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        self.fc22 = nn.Linear(32 * 32, 800)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        self.fc23 = nn.Linear(800, 360)\n",
    "        self.fc24 = nn.Linear(360, 480)\n",
    "        self.fc25 = nn.Linear(480, 240)\n",
    "        self.fc26 = nn.Linear(240, 120)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(120, 90)\n",
    "        self.fc3 = nn.Linear(90, 24)\n",
    "        self.fc4 = nn.Linear(24, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc21(x))\n",
    "        x = self.d1(x)\n",
    "        x = F.leaky_relu(self.fc22(x))\n",
    "        x = self.d2(x)\n",
    "        x = F.leaky_relu(self.fc23(x))\n",
    "        x = F.leaky_relu(self.fc24(x))\n",
    "        x = F.leaky_relu(self.fc25(x))\n",
    "        x = F.leaky_relu(self.fc26(x))\n",
    "        x = self.d3(x)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net1().to(device)\n",
    "\n",
    "set_transforms(end_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(Net1().to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net1().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeakyRelu Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.d1 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 256)\n",
    "        self.d2 = nn.Dropout(0.4)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.d3 = nn.Dropout(0.4)\n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.fc8 = nn.Linear(32, 16)\n",
    "        self.d4 = nn.Dropout(0.4)\n",
    "        self.fc9 = nn.Linear(16, 16)\n",
    "        self.fc10 = nn.Linear(16, 10)\n",
    "        self.d5 = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.d1(x)\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = F.leaky_relu(self.fc4(x))\n",
    "        x = self.d2(x)\n",
    "        x = F.leaky_relu(self.fc5(x))\n",
    "        x = F.leaky_relu(self.fc6(x))\n",
    "        x = self.d3(x)\n",
    "        x = F.leaky_relu(self.fc7(x))\n",
    "        x = F.leaky_relu(self.fc8(x))\n",
    "        x = self.d4(x)\n",
    "        x = F.leaky_relu(self.fc9(x))\n",
    "        x = F.leaky_relu(self.fc10(x))\n",
    "        x = self.d5(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net2().to(device)\n",
    "\n",
    "set_transforms(end_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing Net2 model\n"
     ]
    }
   ],
   "source": [
    "visualize_model(Net2().to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relu ELU LeakyRelu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n",
    "        self.d1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.d2 = nn.Dropout(0.3)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 16)\n",
    "        self.fc7 = nn.Linear(16, 10)\n",
    "        self.d3 = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.d1(x)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))  \n",
    "        x = self.fc4(x)\n",
    "        x = self.d2(x)\n",
    "        x = F.elu(self.fc5(x))\n",
    "        x = F.leaky_relu(self.fc6(x))\n",
    "        x = F.leaky_relu(self.fc7(x))\n",
    "        x = self.d3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net3().to(device)\n",
    "\n",
    "set_transforms(end_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(Net3().to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Arquitecturas CNNs\n",
    "\n",
    "Extienda el análisis utilizando capas convolucionales y reportar el mejor y peor experimento. ¿Cómo se compara?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc21 = nn.Linear(120, 120)\n",
    "        self.fc22 = nn.Linear(120, 120)\n",
    "        self.fc23 = nn.Linear(120, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc21(x))\n",
    "        x = F.leaky_relu(self.fc22(x))\n",
    "        x = F.leaky_relu(self.fc23(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = NetConv().to(device)\n",
    "\n",
    "set_transforms(end_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(NetConv().to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16\n",
    "\n",
    "Implementación de VGG16 en PyTorch\n",
    "https://blog.paperspace.com/vgg-from-scratch-pytorch/#vgg16-from-scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(7*7*512, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.layer9(x)\n",
    "        x = self.layer10(x)\n",
    "        x = self.layer11(x)\n",
    "        x = self.layer12(x)\n",
    "        x = self.layer13(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = VGG16().to(device)\n",
    "\n",
    "set_transforms(transform_224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(VGG16().to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG19\n",
    "\n",
    "Implementación en Keras de VGG19 de la que basamos nuestra implementación reescribiendola en PyTorch https://github.com/fchollet/deep-learning-models/blob/master/vgg19.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG19, self).__init__()\n",
    "        \n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer14 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer15 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.layer16 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.layer9(x)\n",
    "        x = self.layer10(x)\n",
    "        x = self.layer11(x)\n",
    "        x = self.layer12(x)\n",
    "        x = self.layer13(x)\n",
    "        x = self.layer14(x)\n",
    "        x = self.layer15(x)\n",
    "        x = self.layer16(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net = VGG19().to(device)\n",
    "\n",
    "set_transforms(net.transform)\n",
    "\n",
    "net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(VGG19().to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionNet\n",
    "\n",
    "Implementación de InceptionNet en PyTorch\n",
    "https://www.kaggle.com/code/mohamedmustafa/10-implement-inceptionnet-from-scratch-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, In_Channels, Out_Channels, Kernel_Size, Stride, Padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.Conv = nn.Conv2d(in_channels=In_Channels, out_channels=Out_Channels, kernel_size=Kernel_Size, stride=Stride, padding=Padding)\n",
    "        self.Batch_Norm = nn.BatchNorm2d(num_features=Out_Channels)\n",
    "        self.Activ_Func = nn.ReLU()\n",
    "    \n",
    "    \"\"\"\n",
    "    Ahora construiremos la función forward que define el camino hacia el tensor de entrada dandole a entender al tensor la secuencia de capas que se está atravesando\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, Tensor_Path):\n",
    "        Tensor_Path = self.Conv(Tensor_Path)\n",
    "        Tensor_Path = self.Batch_Norm(Tensor_Path)\n",
    "        Tensor_Path = self.Activ_Func(Tensor_Path)\n",
    "        \n",
    "        return Tensor_Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self,In_Channels, Num_Of_Filters_1x1, Num_Of_Filters_3x3, Num_Of_Filters_5x5, Num_Of_Filters_3x3_Reduce,Num_Of_Filters_5x5_Reduce, Pooling):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        # The In_Channels are the depth of tensor coming from previous layer\n",
    "        # First block contains only filters with kernel size 1x1\n",
    "        self.Block_1 = nn.Sequential(ConvBlock(In_Channels=In_Channels, Out_Channels=Num_Of_Filters_1x1, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0)))\n",
    "        \n",
    "        # Second Block contains filters with kernel size 1x1 followed by 3x3\n",
    "        self.Block_2 = nn.Sequential(\n",
    "            ConvBlock(In_Channels=In_Channels, Out_Channels= Num_Of_Filters_3x3_Reduce, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0)),\n",
    "            ConvBlock(In_Channels=Num_Of_Filters_3x3_Reduce, Out_Channels= Num_Of_Filters_3x3, Kernel_Size=(3,3), Stride=(1,1), Padding=(1,1))\n",
    "        )\n",
    "        \n",
    "        # Third Block same as second block unless we'll replace the 3x3 filter with 5x5 \n",
    "        self.Block_3 = nn.Sequential(\n",
    "            ConvBlock(In_Channels=In_Channels, Out_Channels= Num_Of_Filters_5x5_Reduce, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0)),\n",
    "            ConvBlock(In_Channels=Num_Of_Filters_5x5_Reduce, Out_Channels= Num_Of_Filters_5x5, Kernel_Size=(5,5), Stride=(1,1), Padding=(2,2))\n",
    "        )\n",
    "        \n",
    "        # Fourth Block contains maxpooling layer followed by 1x1 filter\n",
    "        self.Block_4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "            ConvBlock(In_Channels=In_Channels, Out_Channels=Pooling, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0))\n",
    "        )\n",
    "    def forward(self, Tensor_Path):\n",
    "        First_Block_Out = self.Block_1(Tensor_Path)\n",
    "        Second_Block_Out = self.Block_2(Tensor_Path)\n",
    "        Third_Block_Out = self.Block_3(Tensor_Path)\n",
    "        Fourth_Block_Out = self.Block_4(Tensor_Path)\n",
    "        \n",
    "        Concatenated_Outputs = torch.cat([First_Block_Out,Second_Block_Out, Third_Block_Out, Fourth_Block_Out], dim=1) #dim=1 because we want to concatenate in the depth dimension\n",
    "        return Concatenated_Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Auxiliary_Classifier(nn.Module):\n",
    "    def __init__(self, In_Channels, Num_Classes):\n",
    "        super(Auxiliary_Classifier, self).__init__()\n",
    "        self.Adaptive_AvgPool = nn.AdaptiveAvgPool2d(output_size=(4, 4))\n",
    "        self.Conv = nn.Conv2d(in_channels= In_Channels, out_channels=128, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
    "        self.Activ_Func = nn.ReLU()\n",
    "        # in_features=2048 because we should flatten the input tensor which has shape of (batch, 4,4,128) so after flaten the tensor will be (batch, 4*4*128)\n",
    "        # out_features=1024 this number from paper\n",
    "        self.FC_1 = nn.Linear(in_features=2048, out_features=1024) \n",
    "        self.DropOut = nn.Dropout(p=0.7) \n",
    "        self.FC_2 = nn.Linear(in_features=1024, out_features= Num_Classes)\n",
    "    \n",
    "    def forward(self, Tensor_Path):\n",
    "        Tensor_Path = self.Adaptive_AvgPool(Tensor_Path)\n",
    "        Tensor_Path = self.Conv(Tensor_Path)\n",
    "        Tensor_Path = self.Activ_Func(Tensor_Path)\n",
    "        Tensor_Path = torch.flatten(Tensor_Path, 1)\n",
    "        Tensor_Path = self.FC_1(Tensor_Path)\n",
    "        Tensor_Path = self.DropOut(Tensor_Path)\n",
    "        Tensor_Path = self.FC_2(Tensor_Path)\n",
    "        \n",
    "        return Tensor_Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet_V1(nn.Module):\n",
    "    def __init__(self, Out_Classes):\n",
    "        super(InceptionNet_V1, self).__init__()\n",
    "        self.Conv_1 = ConvBlock(In_Channels=3, Out_Channels=64, Kernel_Size=(7,7), Stride=(2,2), Padding=(3,3))\n",
    "        self.MaxPool_1 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(0,0), ceil_mode=True)\n",
    "        self.Conv_2 = ConvBlock(In_Channels=64, Out_Channels=64, Kernel_Size=(1,1), Stride=(1,1), Padding=(0,0))\n",
    "        self.Conv_3 = ConvBlock(In_Channels=64, Out_Channels=192, Kernel_Size=(3,3), Stride=(1,1), Padding=(1,1))\n",
    "        self.MaxPool_2 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(0,0), ceil_mode=True)\n",
    "        self.Inception_3a = InceptionBlock(In_Channels=192, Num_Of_Filters_1x1=64, Num_Of_Filters_3x3=128\n",
    "                                          , Num_Of_Filters_5x5=32, Num_Of_Filters_3x3_Reduce=96, \n",
    "                                           Num_Of_Filters_5x5_Reduce=16, Pooling=32)\n",
    "        \n",
    "        self.Inception_3b = InceptionBlock(In_Channels=256, Num_Of_Filters_1x1=128, Num_Of_Filters_3x3=192\n",
    "                                          , Num_Of_Filters_5x5=96, Num_Of_Filters_3x3_Reduce=128, \n",
    "                                           Num_Of_Filters_5x5_Reduce=32, Pooling=64)\n",
    "        \n",
    "        self.MaxPool_3 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(0,0), ceil_mode=True)\n",
    "        self.Inception_4a = InceptionBlock(In_Channels=480, Num_Of_Filters_1x1=192, Num_Of_Filters_3x3=208\n",
    "                                          , Num_Of_Filters_5x5=48, Num_Of_Filters_3x3_Reduce=96, \n",
    "                                           Num_Of_Filters_5x5_Reduce=16, Pooling=64)\n",
    "        \n",
    "        self.Inception_4b = InceptionBlock(In_Channels=512, Num_Of_Filters_1x1=160, Num_Of_Filters_3x3=224\n",
    "                                          , Num_Of_Filters_5x5=64, Num_Of_Filters_3x3_Reduce=112, \n",
    "                                           Num_Of_Filters_5x5_Reduce=24, Pooling=64)\n",
    "        \n",
    "        \n",
    "        self.Inception_4c = InceptionBlock(In_Channels=512, Num_Of_Filters_1x1=128, Num_Of_Filters_3x3=256\n",
    "                                          , Num_Of_Filters_5x5=64, Num_Of_Filters_3x3_Reduce=128, \n",
    "                                           Num_Of_Filters_5x5_Reduce=24, Pooling=64)\n",
    "        \n",
    "       \n",
    "        self.Inception_4d = InceptionBlock(In_Channels=512, Num_Of_Filters_1x1=112, Num_Of_Filters_3x3=288\n",
    "                                          , Num_Of_Filters_5x5=64, Num_Of_Filters_3x3_Reduce=144, \n",
    "                                           Num_Of_Filters_5x5_Reduce=32, Pooling=64) \n",
    "        \n",
    "        self.Inception_4e = InceptionBlock(In_Channels=528, Num_Of_Filters_1x1=256, Num_Of_Filters_3x3=320\n",
    "                                          , Num_Of_Filters_5x5=128, Num_Of_Filters_3x3_Reduce=160, \n",
    "                                           Num_Of_Filters_5x5_Reduce=32, Pooling=128) \n",
    "        \n",
    "        self.MaxPool_4 = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(0,0), ceil_mode=True)\n",
    "        self.Inception_5a = InceptionBlock(In_Channels=832, Num_Of_Filters_1x1=256, Num_Of_Filters_3x3=320\n",
    "                                          , Num_Of_Filters_5x5=128, Num_Of_Filters_3x3_Reduce=160, \n",
    "                                           Num_Of_Filters_5x5_Reduce=32, Pooling=128) \n",
    "        \n",
    "        self.Inception_5b = InceptionBlock(In_Channels=832, Num_Of_Filters_1x1=384, Num_Of_Filters_3x3=384\n",
    "                                          , Num_Of_Filters_5x5=128, Num_Of_Filters_3x3_Reduce=192, \n",
    "                                           Num_Of_Filters_5x5_Reduce=48, Pooling=128) \n",
    "        \n",
    "        self.AvgPool_1 = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.DropOut = nn.Dropout(p=0.4)\n",
    "        self.FC = nn.Linear(in_features=1024, out_features=Out_Classes)\n",
    "        \n",
    "        self.Auxiliary_4a = Auxiliary_Classifier(In_Channels=512, Num_Classes=Out_Classes)\n",
    "        self.Auxiliary_4d = Auxiliary_Classifier(In_Channels=528, Num_Classes=Out_Classes)\n",
    "        \n",
    "    def forward(self, Tensor_Path):\n",
    "        Tensor_Path = self.Conv_1(Tensor_Path)\n",
    "        Tensor_Path = self.MaxPool_1(Tensor_Path)\n",
    "        Tensor_Path = self.Conv_2(Tensor_Path)\n",
    "        Tensor_Path = self.Conv_3(Tensor_Path)\n",
    "        Tensor_Path = self.MaxPool_2(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_3a(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_3b(Tensor_Path)\n",
    "        Tensor_Path = self.MaxPool_3(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4a(Tensor_Path)\n",
    "        Auxiliary_1 = self.Auxiliary_4a(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4b(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4c(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4d(Tensor_Path)\n",
    "        Auxiliary_2 = self.Auxiliary_4d(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_4e(Tensor_Path)\n",
    "        Tensor_Path = self.MaxPool_4(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_5a(Tensor_Path)\n",
    "        Tensor_Path = self.Inception_5b(Tensor_Path)\n",
    "        Tensor_Path = self.AvgPool_1(Tensor_Path)\n",
    "        Tensor_Path = torch.flatten(Tensor_Path, 1)\n",
    "        Tensor_Path = self.DropOut(Tensor_Path)\n",
    "        Tensor_Path = self.FC(Tensor_Path)\n",
    "        \n",
    "        return Tensor_Path, Auxiliary_1, Auxiliary_2\n",
    "\n",
    "# InceptionNet_V1 Necesita AdaptiveAVGPool con input dim no divisibles por output dim, pero no se encuentra implementado para MPS, se puede corrar con CUDA o CPU\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "net = InceptionNet_V1(10).to(device)\n",
    "\n",
    "set_transforms(transform_224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'MPS':\n",
    "    model = InceptionNet_V1(10).to(\"cpu\")\n",
    "\n",
    "    set_transforms(transform_224)\n",
    "    dataiter = iter(test_loader)\n",
    "    data = next(dataiter)\n",
    "    test_images, test_labels = data[0].to(\"cpu\"), data[1].to(\"cpu\")\n",
    "\n",
    "    x = test_images[0]\n",
    "    x = x.to(\"cpu\")\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "    y, aux1, aux2 = model(x)\n",
    "\n",
    "    make_dot(y, params=dict(model.named_parameters())).render(f\"plots/InceptionNet_V1/dot.gv\", view=True)\n",
    "\n",
    "    nn_graph = draw_graph(model, x, expand_nested=True)\n",
    "\n",
    "    nn_graph.visual_graph.render(f\"plots/InceptionNet_V1/graph.gv\", view=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet https://arxiv.org/abs/1512.03385\n",
    "\n",
    "Implementación de ResNet en PyTorch https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            \n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "net = ResNet(ResidualBlock, [2, 2, 2, 2]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(ResNet(ResidualBlock, [2, 2, 2, 2]).to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transforms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar transformaciones de data augmentation antes de las transformaciones finales\n",
    "\n",
    "cur_transform = get_transforms()\n",
    "if cur_transform.transforms[0].__class__.__name__ != 'Compose':\n",
    "    cur_transform.transforms.insert(0, aug_transform)\n",
    "    set_transforms(cur_transform)\n",
    "\n",
    "get_transforms()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizadores\n",
    "\n",
    "Realizar experimentos evaluando distintos optimizadores, schedulers y reportar el mejor y peor experimento. ¿Qué estrategia utilizaron? ¿Qué resultados obtuvieron?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(ResidualBlock, [2, 2, 2, 2]).to(device)\n",
    "set_transforms(transform_224)\n",
    "\n",
    "## Parámetros de entrenamiento\n",
    "learning_rate = 0.05\n",
    "momentum = 0.5\n",
    "epochs = 10\n",
    "\n",
    "weight_decay = 0.0005\n",
    "\n",
    "step_size = 4\n",
    "gamma = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizador y función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizers = {\n",
    "    \"SGD\": optim.SGD(\n",
    "            net.parameters(),\n",
    "            lr=learning_rate,\n",
    "            momentum=momentum,\n",
    "            #weight_decay=weight_decay\n",
    "        ),\n",
    "    \"RMSprop\": optim.RMSprop(\n",
    "        net.parameters(),\n",
    "        lr=learning_rate,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    ),\n",
    "    \"Adam\": optim.Adam(\n",
    "        net.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "}\n",
    "\n",
    "optimizer = optimizers[\"SGD\"]\n",
    "\n",
    "schedulers = {\n",
    "    \"StepLR\": StepLR(\n",
    "        optimizer,\n",
    "        step_size=step_size,\n",
    "        gamma=gamma\n",
    "    ),\n",
    "    \"MultiStepLR\": MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=[4, 8, 12],\n",
    "        gamma=gamma\n",
    "    ),\n",
    "    \"CosineAnnealingLR\": CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max = 32,\n",
    "        eta_min = learning_rate,\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "scheduler = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrenamiento\n",
    "\n",
    "Realizar experimentos evaluando distintos batch-sizes, epochs y reportar el mejor y peor experimento. ¿Qué resultados obtuvieron?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración Wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet optimizer=SGD  lr=0.05 momentum=0.5 epochs=10 device=mps:0'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nombre del experimento\n",
    "project_name = \"TP3\"\n",
    "experiment_name = f\"{net.__class__.__name__ } optimizer={optimizer.__class__.__name__}  lr={learning_rate} momentum={momentum} epochs={epochs} device={device}\"\n",
    "experiment_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nacho/Desktop/code/TP3_TDVI/wandb/run-20231105_180307-min758tr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pardo/TP3/runs/min758tr' target=\"_blank\">Net1 optimizer=SGD  lr=0.1 momentum=0.9 epochs=10 device=mps:0</a></strong> to <a href='https://wandb.ai/pardo/TP3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pardo/TP3' target=\"_blank\">https://wandb.ai/pardo/TP3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pardo/TP3/runs/min758tr' target=\"_blank\">https://wandb.ai/pardo/TP3/runs/min758tr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/pardo/TP3/runs/min758tr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1cb9f74f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "wandb.init(\n",
    "    # seteamos el projecto donde se va a guardar el experimento en wandb\n",
    "    project=project_name,\n",
    "    name=experiment_name,\n",
    "    \n",
    "    # trackeamos los hiperparámetros y las métricas\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"momentum\": momentum,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones de entranamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_InceptionV1(model, train_loader, val_loader, num_of_train_samples, num_of_val_samples, criterion, optimizer, epochs, log, scheduler=None):\n",
    "    iterator = tqdm(\n",
    "        range(epochs),\n",
    "        total=epochs,\n",
    "        desc=\"Epoch\"\n",
    "    )\n",
    "\n",
    "    # --------------------------------- TRAIN SET -----------------------------#\n",
    "    \n",
    "    # La accuracy y la loss de train y validation se guardan en estas listas por epoch\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    val_loss_history = []\n",
    "    val_accuracy_history = []\n",
    "\n",
    "    train_accuracy = 0\n",
    "    val_accuracy = 0\n",
    "    train_cummulative_loss = 0\n",
    "    val_cummulative_loss = 0\n",
    "    \n",
    "    for epoch in iterator:\n",
    "\n",
    "        num_of_predicted_correctly = 0 # numero de predicciones correctas\n",
    "        train_cummulative_loss = 0 # suma de las loss de cada batch\n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            batch_samples, targets = data\n",
    "            batch_samples = batch_samples.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            \n",
    "            # pasa las muestras de train por la red (Forward Path)\n",
    "            network_predictions, aux_1_predictions, aux_2_predictions = model(batch_samples)\n",
    "            \n",
    "            # Network Loss contiene la loss promedio de cada batch\n",
    "            network_loss = criterion(network_predictions, targets)\n",
    "            aux_1_loss = criterion(aux_1_predictions, targets)\n",
    "            aux_2_loss = criterion(aux_2_predictions, targets)\n",
    "            \n",
    "            # Pondera las losses de cada bloque de la red como dice el paper\n",
    "            main_loss = network_loss + (0.3 * aux_1_loss) + (0.3 * aux_2_loss)\n",
    "            \n",
    "            # Backward Propagation\n",
    "            optimizer.zero_grad() # gradientes a cero\n",
    "            main_loss.backward() # backpropagation\n",
    "            optimizer.step() # actualizacion de pesos\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            _, train_samples_predictions = network_predictions.max(1)\n",
    "            train_samples_predictions = train_samples_predictions.to(device=device)\n",
    "            num_of_predicted_correctly += (train_samples_predictions == targets).float().sum().item()\n",
    "            train_cummulative_loss += main_loss.data.item() * batch_samples.shape[0]\n",
    "            \n",
    "            iterator.set_postfix(\n",
    "                {\n",
    "                    \"train_accuracy\": train_accuracy,\n",
    "                    \"val_accuracy\": val_accuracy,\n",
    "                    \"train_loss\": train_cummulative_loss,\n",
    "                    \"val_loss\": val_cummulative_loss,\n",
    "                    \"train iter\": i,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        train_cummulative_loss /= num_of_train_samples\n",
    "        train_loss_history.append(train_cummulative_loss)\n",
    "        train_accuracy = 100 * num_of_predicted_correctly / num_of_train_samples\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "\n",
    "    \n",
    "    #----------------------------- VALIDATION SET -----------------------------#\n",
    "    \n",
    "        num_of_predicted_correctly = 0\n",
    "        with torch.no_grad(): # Como estamos en validacion no necesitamos calcular los gradientes\n",
    "            val_cummulative_loss = 0\n",
    "            for batch_samples,targets in val_loader:\n",
    "                batch_samples = batch_samples.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                # psamos los samples de validacion por la red (Forward Path)\n",
    "                network_predictions, aux_1_predictions, aux_2_predictions = model(batch_samples)\n",
    "\n",
    "                # Network loss guarda la loss promedio de cada batch\n",
    "                network_loss = criterion(network_predictions, targets)\n",
    "                aux_1_loss = criterion(aux_1_predictions, targets)\n",
    "                aux_2_loss = criterion(aux_2_predictions, targets)\n",
    "\n",
    "                # Pondera las losses de cada bloque de la red como dice el paper\n",
    "                main_loss = network_loss + (0.3 * aux_1_loss) + (0.3 * aux_2_loss)\n",
    "\n",
    "                _, val_samples_predictions = network_predictions.max(1)\n",
    "                val_samples_predictions = val_samples_predictions.to(device=device)\n",
    "                num_of_predicted_correctly += (val_samples_predictions == targets).float().sum().item()\n",
    "                val_cummulative_loss += main_loss.data.item() * batch_samples.shape[0]\n",
    "            \n",
    "            val_cummulative_loss /= num_of_val_samples\n",
    "            val_loss_history.append(val_cummulative_loss)\n",
    "            val_accuracy = 100 * num_of_predicted_correctly / num_of_val_samples\n",
    "            val_accuracy_history.append(val_accuracy)\n",
    "\n",
    "            if log:   \n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"train_accuracy\": train_accuracy,\n",
    "                        \"val_accuracy\": val_accuracy,\n",
    "                        \"train_loss\": train_cummulative_loss,\n",
    "                        \"val_loss\": val_cummulative_loss,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            iterator.set_postfix(\n",
    "                {\n",
    "                    \"train_accuracy\": train_accuracy,\n",
    "                    \"val_accuracy\": val_accuracy,\n",
    "                    \"train_loss\": train_cummulative_loss,\n",
    "                    \"val_loss\": val_cummulative_loss,\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    torch.save(model.state_dict(), \"InceptionNet_Model\")\n",
    "    return train_accuracy, val_accuracy, train_cummulative_loss, val_cummulative_loss\n",
    "\n",
    "def propagate_InceptionNetwork(model, optimizer, criterion, epochs, log, scheduler=None):\n",
    "    if type(model) == InceptionNet_V1:    \n",
    "        return train_InceptionV1(\n",
    "            model = model, \n",
    "            train_loader = train_loader,\n",
    "            val_loader = val_loader,\n",
    "            num_of_train_samples = 40000,\n",
    "            num_of_val_samples = 10000,\n",
    "            criterion = criterion,\n",
    "            optimizer = optimizer,\n",
    "            epochs = epochs,\n",
    "            log = log, \n",
    "            scheduler = scheduler\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Modelo no es InceptionNetV1\")\n",
    "    \n",
    "def propagate_network(net, optimizer, criterion, epochs, log, scheduler=None):\n",
    "    iterator = tqdm(\n",
    "        range(epochs),\n",
    "        total=epochs,\n",
    "        desc=\"Epoch\"\n",
    "    )\n",
    "\n",
    "    train_accuracy = 0\n",
    "    val_accuracy = 0\n",
    "    running_loss = 0\n",
    "    val_loss = 0   \n",
    "    \n",
    "    for epoch in iterator:\n",
    "        \n",
    "        # ---------------- SECCION DE TRAIN -----------------\n",
    "\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "            # Los datos son una lista de [inputs, labels]\n",
    "            # inputs, labels = data\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Reiniciamos gradientes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs) # forward\n",
    "            loss = criterion(outputs, labels) # perdida\n",
    "            loss.backward() # backward\n",
    "            optimizer.step() # optimizacion\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            iterator.set_postfix(\n",
    "                {\n",
    "                    \"train_accuracy\": train_accuracy,\n",
    "                    \"val_accuracy\": val_accuracy,\n",
    "                    \"train_loss\": running_loss,\n",
    "                    \"val_loss\": val_loss,\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        # ---------------- SECCION DE VALIDACION ----------------\n",
    "        \n",
    "        train_accuracy = 100 * train_correct / total\n",
    "        running_loss = running_loss / total\n",
    "\n",
    "        val_correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # Esta parte es sólo validación, no requiere entrenar, por lo que no calculamos gradientes.\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                \n",
    "                # Calculamos las salidas de la red para las imágenes de validación\n",
    "                outputs = net(images)\n",
    "                \n",
    "                # La clase con mayor valor de salida es la predicción de la red\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "        # Fin de la validación\n",
    "\n",
    "        val_accuracy = 100 * val_correct / total\n",
    "        val_loss = val_loss / total\n",
    "\n",
    "        if log:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"train_accuracy\": train_accuracy,\n",
    "                    \"val_accuracy\": val_accuracy,\n",
    "                    \"train_loss\": running_loss,\n",
    "                    \"val_loss\": val_loss,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        iterator.set_postfix(\n",
    "            {\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"train_loss\": running_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    return train_accuracy, val_accuracy, running_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, criterion, optimizer, epochs, log, scheduler=None):\n",
    "    try:\n",
    "        if net.__class__.__name__ == \"InceptionNet_V1\":\n",
    "            return propagate_InceptionNetwork(net, optimizer, criterion, epochs, log, scheduler)\n",
    "        else:\n",
    "            return propagate_network(net, optimizer, criterion, epochs, log, scheduler)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, val_acc, train_loss, val_loss = train_model(net, criterion, optimizer, epochs, False, scheduler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Exploración de Hiperparametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "best_params = {\n",
    "    \"learning_rate\": 0,\n",
    "    \"momentum\": 0,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"train_accuracy\": 0,\n",
    "    \"val_accuracy\": 0,\n",
    "}\n",
    "\n",
    "# Optimizador y función de pérdida\n",
    "learning_rates = [0.005, 0.001, 0.0005, 0.0001, 0.1]\n",
    "momentums = [0, 0.5, 0.9, 0.99]\n",
    "models = [\"NetConv\", \"VGG16\", \"VGG19\", \"ResNet\", \"InceptionNet_V1\"]\n",
    "for lr in learning_rates:\n",
    "    for momentum in momentums:\n",
    "        for model in models:\n",
    "            if model == \"NetConv\":\n",
    "                net = NetConv().to(device)\n",
    "            elif model == \"VGG16\":\n",
    "                net = VGG16().to(device)\n",
    "            elif model == \"VGG19\":\n",
    "                net = VGG19().to(device)\n",
    "            elif model == \"ResNet\":\n",
    "                net = ResNet(ResidualBlock, [2, 2, 2, 2]).to(device)\n",
    "            elif model == \"InceptionNet_V1\":\n",
    "                net = InceptionNet_V1(10).to(device)\n",
    "            \n",
    "            optimizer = optim.SGD(\n",
    "                net.parameters(),\n",
    "                lr=lr,\n",
    "                momentum=momentum,\n",
    "                #weight_decay=0.0005,\n",
    "            )\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            wandb.init(\n",
    "                # seteamos el projecto donde se va a guardar el experimento en wandb\n",
    "                project=project_name,\n",
    "                name=f\"{net.__class__.__name__ } {optimizer.__class__.__name__} lr={lr} momentum={momentum} epochs={epochs} device={device}\",\n",
    "                # trackeamos los hiperparámetros y las métricas\n",
    "                config={\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"momentum\": momentum,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"epochs\": epochs,\n",
    "                },\n",
    "            )\n",
    "            train_accuracy, val_accuracy, train_loss, val_loss = train_model(net, criterion, optimizer, epochs)\n",
    "\n",
    "            if val_accuracy > best_params[\"val_accuracy\"]:\n",
    "                best_params[\"learning_rate\"] = lr\n",
    "                best_params[\"momentum\"] = momentum\n",
    "                best_params[\"train_accuracy\"] = train_accuracy\n",
    "                best_params[\"val_accuracy\"] = val_accuracy\n",
    "                best_params[\"train_loss\"] = train_loss\n",
    "                best_params[\"val_loss\"] = val_loss\n",
    "\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Guardar el Modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de guardar el modelo. Sin embargo lo deberiamos guardar para el que mejor dio en validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './{}.pth'.format(experiment_name)\n",
    "torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluación final\n",
    "\n",
    "Evaluar el mejor modelo, es decir, el mejor de los ejercicios anteriores, con el set de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Net()\n",
    "#net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "data = next(dataiter)\n",
    "test_images, test_labels = data\n",
    "\n",
    "# print test_images\n",
    "imshow(torchvision.utils.make_grid(test_images))\n",
    "print(\"GroundTruth: \", \" \".join(f\"{classes[test_labels[j]]:5s}\" for j in range(batch_size)))\n",
    "\n",
    "test_images, test_labels = data[0].to(device), data[1].to(device)\n",
    "outputs = net(test_images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        test_images, test_labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running test_images through the network\n",
    "        outputs = net(test_images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the 10000 test test_images: {100 * correct // total} %\")\n",
    "\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        test_images, test_labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(test_images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(test_labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f\"Accuracy for class: {classname:5s} is {accuracy:.1f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar Metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_metadata(model, exp_name, optimizer, criterion, epochs, train_acc, train_loss, val_acc, val_loss, regularizations):\n",
    "    return {\n",
    "        \"name\": exp_name,\n",
    "        \"model_class\": str(model.__class__.__name__),\n",
    "        \"model_type\": str(model.__class__.__name__),\n",
    "        \"layers\": repr(model).replace(\"\\n\", \"\"),\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": str(optimizer.__class__.__name__),\n",
    "        \"optimizer_params\": str(optimizer.__dict__),\n",
    "        \"loss\": str(criterion.__class__.__name__),\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"regularizations\": str(regularizations),\n",
    "    }\n",
    "\n",
    "def save_metadata(metadata, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(metadata, f,  sort_keys=True, indent=4, separators=(',', ': '))\n",
    "\n",
    "\n",
    "net = ResNet(ResidualBlock, [2, 2, 2, 2]).to(device)\n",
    "experiment_name = \"ResNet SGD lr=0.01 momentum=0.8 epochs=12 device=cuda:0\"\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.8,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_acc = 99.9525\n",
    "train_loss = 0.00038689298745580344\n",
    "val_acc = 85.81\n",
    "val_loss = 0.05476715290141001\n",
    "\n",
    "regs={}\n",
    "\n",
    "metadata = gen_metadata(\n",
    "    net, \n",
    "    experiment_name, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    epochs, \n",
    "    train_acc, \n",
    "    train_loss, \n",
    "    val_acc, \n",
    "    val_loss, \n",
    "    regularizations=regs,\n",
    ")\n",
    "\n",
    "save_metadata(\n",
    "        metadata,\n",
    "        f\"metadata/{experiment_name}.json\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDVI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
